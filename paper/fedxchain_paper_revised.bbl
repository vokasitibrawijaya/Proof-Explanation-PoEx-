% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in \emph{Proceedings of the 20th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, ser. Proceedings of
  Machine Learning Research, vol.~54.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2017, pp. 1273--1282.

\bibitem{kairouz2019advances}
P.~Kairouz, H.~B. McMahan, B.~Avent, A.~Bellet, M.~Bennis, A.~N. Bhagoji
  \emph{et~al.}, ``Advances and open problems in federated learning,''
  \emph{arXiv preprint arXiv:1912.04977}, 2019.

\bibitem{rieke2020future}
N.~Rieke, J.~Hancox, W.~Li, F.~Milletari, H.~R. Roth, S.~Albarqouni
  \emph{et~al.}, ``The future of digital health with federated learning,''
  \emph{NPJ Digital Medicine}, vol.~3, no.~1, pp. 1--7, 2020.

\bibitem{yang2019federated}
Q.~Yang, Y.~Liu, T.~Chen, and Y.~Tong, ``Federated machine learning: Concept
  and applications,'' \emph{ACM Transactions on Intelligent Systems and
  Technology (TIST)}, vol.~10, no.~2, pp. 1--19, 2019.

\bibitem{li2020federated}
T.~Li, A.~K. Sahu, M.~Zaheer, M.~Sanjabi, A.~Talwalkar, and V.~Smith,
  ``Federated optimization in heterogeneous networks,'' in \emph{Proceedings of
  Machine Learning and Systems (MLSys)}, 2020, pp. 429--450.

\bibitem{karimireddy2020scaffold}
S.~P. Karimireddy, S.~Kale, M.~Mohri, S.~Reddi, S.~Stich, and A.~T. Suresh,
  ``Scaffold: Stochastic controlled averaging for federated learning,'' in
  \emph{Proceedings of the 37th International Conference on Machine Learning
  (ICML)}, 2020, pp. 5132--5143.

\bibitem{fung2020mitigating}
C.~Fung, C.~J. Yoon, and I.~Beschastnikh, ``Mitigating sybils in federated
  learning poisoning,'' \emph{arXiv preprint arXiv:1808.04866}, 2020.

\bibitem{blanchard2017machine}
P.~Blanchard, E.~M. El~Mhamdi, R.~Guerraoui, and J.~Stainer, ``Machine learning
  with adversaries: Byzantine tolerant gradient descent,'' in \emph{Advances in
  Neural Information Processing Systems (NeurIPS)}, vol.~30, 2017, pp.
  119--129.

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin, ``Why should i trust you?: Explaining
  the predictions of any classifier,'' in \emph{Proceedings of the 22nd ACM
  SIGKDD International Conference on Knowledge Discovery and Data Mining},
  2016, pp. 1135--1144.

\bibitem{lundberg2017unified}
S.~M. Lundberg and S.-I. Lee, ``A unified approach to interpreting model
  predictions,'' in \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, vol.~30, 2017, pp. 4765--4774.

\bibitem{zhao2018federated}
Y.~Zhao, M.~Li, L.~Lai, N.~Suda, D.~Civin, and V.~Chandra, ``Federated learning
  with non-iid data,'' \emph{arXiv preprint arXiv:1806.00582}, 2018.

\bibitem{konecny2016federated}
J.~Konečný, H.~B. McMahan, F.~X. Yu, P.~Richtárik, A.~T. Suresh, and
  D.~Bacon, ``Federated learning: Strategies for improving communication
  efficiency,'' \emph{arXiv preprint arXiv:1610.05492}, 2016.

\bibitem{li2020convergence}
X.~Li, K.~Huang, W.~Yang, S.~Wang, and Z.~Zhang, ``On the convergence of fedavg
  on non-iid data,'' in \emph{Proceedings of the International Conference on
  Learning Representations (ICLR)}, 2020.

\bibitem{yin2018byzantine}
D.~Yin, Y.~Chen, R.~Kannan, and P.~Bartlett, ``Byzantine-robust distributed
  learning: Towards optimal statistical rates,'' in \emph{Proceedings of the
  35th International Conference on Machine Learning (ICML)}, 2018, pp.
  5650--5659.

\bibitem{kang2019incentive}
J.~Kang, Z.~Xiong, D.~Niyato, S.~Xie, and J.~Zhang, ``Incentive mechanism for
  reliable federated learning: A joint optimization approach to combining
  reputation and contract theory,'' \emph{IEEE Internet of Things Journal},
  vol.~6, no.~6, pp. 10\,700--10\,714, 2019.

\bibitem{wang2020federated}
H.~Wang, Z.~Kaplan, D.~Niu, and B.~Li, ``Optimizing federated learning on
  non-iid data with reinforcement learning,'' in \emph{Proceedings of IEEE
  INFOCOM 2020}, 2020, pp. 1698--1707.

\bibitem{shen2021explainable}
T.~Shen, J.~Zhang, X.~Jia, F.~Zhang, G.~Huang, P.~Zhou, F.~Kuang, X.~Wu, and
  S.~Wu, ``Federated mutual learning,'' \emph{arXiv preprint arXiv:2006.16765},
  2021.

\bibitem{kim2019blockchained}
H.~Kim, J.~Park, M.~Bennis, and S.-L. Kim, ``Blockchained on-device federated
  learning,'' \emph{IEEE Communications Letters}, vol.~24, no.~6, pp.
  1279--1283, 2019.

\bibitem{li2020blockchain}
Y.~Li, C.~Chen, N.~Liu, H.~Huang, Z.~Zheng, and Q.~Yan, ``A blockchain-based
  decentralized federated learning framework with committee consensus,''
  \emph{IEEE Network}, vol.~35, no.~1, pp. 234--241, 2020.

\bibitem{nguyen2021federated}
D.~C. Nguyen, M.~Ding, P.~N. Pathirana, A.~Seneviratne, J.~Li, and H.~V. Poor,
  ``Federated learning for internet of things: A comprehensive survey,''
  \emph{IEEE Communications Surveys \& Tutorials}, vol.~23, no.~3, pp.
  1622--1658, 2021.

\bibitem{wolberg1995breast}
W.~H. Wolberg, W.~N. Street, and O.~L. Mangasarian, ``Breast cancer wisconsin
  (diagnostic) data set,'' UCI Machine Learning Repository, 1995.

\end{thebibliography}
